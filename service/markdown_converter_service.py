from marker.converters.pdf import PdfConverter
from marker.models import create_model_dict
from marker.config.parser import ConfigParser
import dotenv
import os

"""
Markdown è½¬æ¢æœåŠ¡æ¨¡å—
åŸºäº marker åº“å®ç°æ–‡ä»¶åˆ° Markdown çš„è½¬æ¢
å‚è€ƒ: https://github.com/datalab-to/marker

æ³¨æ„ï¼šmarker æ¨¡å—ä½¿ç”¨å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¯åŠ¨æ—¶ä¸‹è½½æ¨¡å‹
"""
import tempfile
from typing import Optional, Dict, Any
from pathlib import Path

# åŠ è½½ .env æ–‡ä»¶
dotenv.load_dotenv()

# å»¶è¿Ÿå¯¼å…¥ marker æ¨¡å—ï¼Œé¿å…å¯åŠ¨æ—¶ä¸‹è½½æ¨¡å‹
# è¿™äº›æ¨¡å—ä¼šåœ¨å®é™…ä½¿ç”¨æ—¶æ‰å¯¼å…¥


class MarkdownConverterService:
    """
    Markdown è½¬æ¢æœåŠ¡ç±»

    æ”¯æŒå°† PDFã€å›¾ç‰‡ã€PPTXã€DOCXã€XLSXã€HTMLã€EPUB ç­‰æ–‡ä»¶è½¬æ¢ä¸º Markdown æ ¼å¼
    åŸºäº marker åº“å®ç°é«˜ç²¾åº¦è½¬æ¢
    """

    def __init__(
        self,
        use_llm: Optional[bool] = None,
        force_ocr: Optional[bool] = None,
        disable_image_extraction: Optional[bool] = None,
        output_format: Optional[str] = None,
        llm_service: Optional[str] = None,
        llm_api_key: Optional[str] = None,
        llm_base_url: Optional[str] = None,
        llm_model: Optional[str] = None,
        max_file_size_mb: Optional[int] = None,
        max_batch_files: Optional[int] = None,
        max_concurrent: Optional[int] = None,
    ):
        """
        åˆå§‹åŒ– Markdown è½¬æ¢æœåŠ¡

        å‚æ•°:
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM æå‡è½¬æ¢ç²¾åº¦ (é»˜è®¤ä» MARKDOWN_USE_LLM ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ False)
            force_ocr: æ˜¯å¦å¼ºåˆ¶å¯¹æ‰€æœ‰å†…å®¹è¿›è¡Œ OCR (é»˜è®¤ä» MARKDOWN_FORCE_OCR ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ False)
            disable_image_extraction: æ˜¯å¦ç¦ç”¨å›¾ç‰‡æå– (é»˜è®¤ä» MARKDOWN_DISABLE_IMAGE_EXTRACTION ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ False)
            output_format: è¾“å‡ºæ ¼å¼ (markdown, json, html, chunks) (é»˜è®¤ä» MARKDOWN_OUTPUT_FORMAT ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ markdown)
            llm_service: LLM æœåŠ¡ç±»è·¯å¾„ (é»˜è®¤ä» MARKDOWN_LLM_SERVICE ç¯å¢ƒå˜é‡è¯»å–)
            llm_api_key: LLM API å¯†é’¥ (é»˜è®¤ä» MARKDOWN_LLM_API_KEY ç¯å¢ƒå˜é‡è¯»å–)
            llm_base_url: LLM API åŸºç¡€ URL (é»˜è®¤ä» MARKDOWN_LLM_BASE_URL ç¯å¢ƒå˜é‡è¯»å–)
            llm_model: LLM æ¨¡å‹åç§° (é»˜è®¤ä» MARKDOWN_LLM_MODEL ç¯å¢ƒå˜é‡è¯»å–)
            max_file_size_mb: æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ (é»˜è®¤ä» MARKDOWN_MAX_FILE_SIZE_MB ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ 100)
            max_batch_files: æœ€å¤§æ‰¹å¤„ç†æ–‡ä»¶æ•° (é»˜è®¤ä» MARKDOWN_MAX_BATCH_FILES ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ 50)
            max_concurrent: æœ€å¤§å¹¶å‘æ•° (é»˜è®¤ä» MARKDOWN_MAX_CONCURRENT ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ 50)
        """
        # ä»ç¯å¢ƒå˜é‡è¯»å–åŸºç¡€é…ç½®ï¼Œå¦‚æœå‚æ•°æœªæä¾›åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡å€¼
        self.use_llm = use_llm if use_llm is not None else os.getenv("MARKDOWN_USE_LLM", "false").lower() == "true"
        self.force_ocr = force_ocr if force_ocr is not None else os.getenv("MARKDOWN_FORCE_OCR", "false").lower() == "true"
        self.disable_image_extraction = disable_image_extraction if disable_image_extraction is not None else os.getenv("MARKDOWN_DISABLE_IMAGE_EXTRACTION", "false").lower() == "true"
        self.output_format = output_format or os.getenv("MARKDOWN_OUTPUT_FORMAT", "markdown")

        # ä»ç¯å¢ƒå˜é‡è¯»å–æ–‡ä»¶é™åˆ¶é…ç½®
        self.max_file_size_mb = max_file_size_mb or int(os.getenv("MARKDOWN_MAX_FILE_SIZE_MB", "100"))
        self.max_batch_files = max_batch_files or int(os.getenv("MARKDOWN_MAX_BATCH_FILES", "50"))
        self.max_concurrent = max_concurrent or int(os.getenv("MARKDOWN_MAX_CONCURRENT", "50"))

        # ä»ç¯å¢ƒå˜é‡è¯»å– LLM é…ç½®
        self.llm_service = llm_service or os.getenv("MARKDOWN_LLM_SERVICE")
        self.llm_api_key = llm_api_key or os.getenv("MARKDOWN_LLM_API_KEY")
        self.llm_base_url = llm_base_url or os.getenv("MARKDOWN_LLM_BASE_URL")
        self.llm_model = llm_model or os.getenv("MARKDOWN_LLM_MODEL")

        # æ„å»ºé…ç½®å­—å…¸
        self.config = {
            "output_format": self.output_format,
            "use_llm": self.use_llm,
            "force_ocr": self.force_ocr,
            "disable_image_extraction": self.disable_image_extraction,
        }

        # å¦‚æœå¯ç”¨ LLMï¼Œæ·»åŠ  LLM ç›¸å…³é…ç½®
        if self.use_llm and self.llm_service:
            self.config["llm_service"] = self.llm_service
            if self.llm_api_key:
                # æ ¹æ®ä¸åŒçš„ LLM æœåŠ¡è®¾ç½®å¯¹åº”çš„ API key å‚æ•°
                if "openai" in self.llm_service.lower():
                    self.config["openai_api_key"] = self.llm_api_key
                    if self.llm_base_url:
                        self.config["openai_base_url"] = self.llm_base_url
                    if self.llm_model:
                        self.config["openai_model"] = self.llm_model
                elif "gemini" in self.llm_service.lower():
                    self.config["gemini_api_key"] = self.llm_api_key
                    if self.llm_model:
                        self.config["gemini_model"] = self.llm_model
                elif "claude" in self.llm_service.lower():
                    self.config["claude_api_key"] = self.llm_api_key
                    if self.llm_model:
                        self.config["claude_model_name"] = self.llm_model
        
        # åˆå§‹åŒ–è½¬æ¢å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œåœ¨å®é™…è½¬æ¢æ—¶åˆ›å»ºï¼‰
        self.converter: Optional[PdfConverter] = None
        
    def _initialize_converter(self) -> None:
        """åˆå§‹åŒ– marker è½¬æ¢å™¨ï¼ˆå»¶è¿Ÿå¯¼å…¥ï¼‰"""
        if self.converter is not None:
            return

        # å»¶è¿Ÿå¯¼å…¥ marker æ¨¡å—ï¼ˆé¿å…å¯åŠ¨æ—¶ä¸‹è½½æ¨¡å‹ï¼‰
        from marker.converters.pdf import PdfConverter
        from marker.models import create_model_dict
        from marker.config.parser import ConfigParser

        # åˆ›å»ºé…ç½®è§£æå™¨
        config_parser = ConfigParser(self.config)

        # åˆ›å»ºè½¬æ¢å™¨
        self.converter = PdfConverter(
            config=config_parser.generate_config_dict(),
            artifact_dict=create_model_dict(),
            processor_list=config_parser.get_processors(),
            renderer=config_parser.get_renderer(),
            llm_service=config_parser.get_llm_service() if self.use_llm else None
        )
        
        print(f"âœ… Markdown è½¬æ¢å™¨åˆå§‹åŒ–æˆåŠŸï¼")
        print(f"   - è¾“å‡ºæ ¼å¼: {self.output_format}")
        print(f"   - ä½¿ç”¨ LLM: {self.use_llm}")
        print(f"   - å¼ºåˆ¶ OCR: {self.force_ocr}")
        print(f"   - ç¦ç”¨å›¾ç‰‡æå–: {self.disable_image_extraction}")
    
    async def convert_file(
        self,
        file_path: str,
        page_range: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è½¬æ¢æ–‡ä»¶ä¸º Markdown

        å‚æ•°:
            file_path: æ–‡ä»¶è·¯å¾„
            page_range: é¡µé¢èŒƒå›´ (ä¾‹å¦‚: "0,5-10,20")

        è¿”å›:
            åŒ…å«è½¬æ¢ç»“æœçš„å­—å…¸:
            {
                "markdown": str,  # Markdown æ–‡æœ¬
                "metadata": dict,  # å…ƒæ•°æ®
                "images": dict,   # å›¾ç‰‡å­—å…¸ (å¦‚æœå¯ç”¨å›¾ç‰‡æå–)
                "success": bool,
                "message": str
            }
        """
        try:
            # ç¡®ä¿è½¬æ¢å™¨å·²åˆå§‹åŒ–
            self._initialize_converter()

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                return {
                    "success": False,
                    "message": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}",
                    "markdown": "",
                    "metadata": {},
                    "images": {}
                }

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
            if file_size_mb > self.max_file_size_mb:
                return {
                    "success": False,
                    "message": f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {file_size_mb:.2f}MB > {self.max_file_size_mb}MB",
                    "markdown": "",
                    "metadata": {},
                    "images": {}
                }
            
            # å¦‚æœæŒ‡å®šäº†é¡µé¢èŒƒå›´ï¼Œæ›´æ–°é…ç½®
            if page_range:
                # è¿™é‡Œå¯ä»¥é€šè¿‡é‡æ–°åˆ›å»ºè½¬æ¢å™¨æ¥åº”ç”¨é¡µé¢èŒƒå›´
                # æš‚æ—¶å…ˆä¸æ”¯æŒåŠ¨æ€é¡µé¢èŒƒå›´
                pass
            
            # æ‰§è¡Œè½¬æ¢
            print(f"ğŸ”„ å¼€å§‹è½¬æ¢æ–‡ä»¶: {file_path}")
            rendered = self.converter(file_path)

            # å»¶è¿Ÿå¯¼å…¥ text_from_rendered
            from marker.output import text_from_rendered

            # æå–æ–‡æœ¬å’Œå›¾ç‰‡
            text, metadata, images = text_from_rendered(rendered)

            # å¦‚æœç¦ç”¨äº†å›¾ç‰‡æå–ï¼Œæ¸…ç©ºå›¾ç‰‡å­—å…¸
            if self.disable_image_extraction:
                images = {}
            else:
                # å°† PIL Image å¯¹è±¡è½¬æ¢ä¸º base64 å­—ç¬¦ä¸²ï¼Œä»¥ä¾¿åºåˆ—åŒ–
                import base64
                from io import BytesIO
                serializable_images = {}
                for key, img in images.items():
                    if hasattr(img, 'save'):  # æ£€æŸ¥æ˜¯å¦æ˜¯ PIL Image
                        buffer = BytesIO()
                        img.save(buffer, format='PNG')
                        img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                        serializable_images[key] = f"data:image/png;base64,{img_base64}"
                    else:
                        serializable_images[key] = img
                images = serializable_images

            print(f"âœ… æ–‡ä»¶è½¬æ¢æˆåŠŸï¼")
            print(f"   - æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
            print(f"   - å›¾ç‰‡æ•°é‡: {len(images)}")

            return {
                "success": True,
                "message": "è½¬æ¢æˆåŠŸ",
                "markdown": text,
                "metadata": metadata,
                "images": images
            }
            
        except Exception as e:
            error_msg = f"è½¬æ¢å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "message": error_msg,
                "markdown": "",
                "metadata": {},
                "images": {}
            }
    
    async def convert_file_bytes(
        self,
        file_bytes: bytes,
        filename: str,
        page_range: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è½¬æ¢æ–‡ä»¶å­—èŠ‚æµä¸º Markdown

        å‚æ•°:
            file_bytes: æ–‡ä»¶å­—èŠ‚æµ
            filename: æ–‡ä»¶åï¼ˆç”¨äºç¡®å®šæ–‡ä»¶ç±»å‹ï¼‰
            page_range: é¡µé¢èŒƒå›´ (ä¾‹å¦‚: "0,5-10,20")

        è¿”å›:
            åŒ…å«è½¬æ¢ç»“æœçš„å­—å…¸
        """
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹ï¼Œå¯¹äº Word æ–‡æ¡£ä½¿ç”¨ mammoth ç›´æ¥å¤„ç†
        file_ext = Path(filename).suffix.lower()

        if file_ext in ['.docx', '.doc']:
            return await self._convert_word_document(file_bytes, filename)

        # å¯¹äºå…¶ä»–æ–‡ä»¶ç±»å‹ï¼Œä½¿ç”¨åŸæœ‰çš„ marker å¤„ç†æ–¹å¼
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_dir = tempfile.mkdtemp()
        temp_file_path = os.path.join(temp_dir, filename)

        try:
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with open(temp_file_path, 'wb') as f:
                f.write(file_bytes)

            # è½¬æ¢æ–‡ä»¶
            result = await self.convert_file(temp_file_path, page_range)

            return result

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if os.path.exists(temp_file_path):
                    os.remove(temp_file_path)
                if os.path.exists(temp_dir):
                    os.rmdir(temp_dir)
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def get_supported_formats(self) -> list[str]:
        """
        è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼åˆ—è¡¨
        
        è¿”å›:
            æ”¯æŒçš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨
        """
        return [
            ".pdf",
            ".png", ".jpg", ".jpeg", ".gif", ".bmp", ".tiff",
            ".pptx", ".ppt",
            ".docx", ".doc",
            ".xlsx", ".xls",
            ".html", ".htm",
            ".epub"
        ]
    
    def is_supported_file(self, filename: str) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ”¯æŒè½¬æ¢

        å‚æ•°:
            filename: æ–‡ä»¶å

        è¿”å›:
            æ˜¯å¦æ”¯æŒ
        """
        file_ext = Path(filename).suffix.lower()
        return file_ext in self.get_supported_formats()

    async def convert_multiple_files(
        self,
        file_paths: list[str],
        page_range: Optional[str] = None,
        max_concurrent: Optional[int] = None
    ) -> list[Dict[str, Any]]:
        """
        å¹¶å‘è½¬æ¢å¤šä¸ªæ–‡ä»¶

        å‚æ•°:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            page_range: é¡µé¢èŒƒå›´ (ä¾‹å¦‚: "0,5-10,20")
            max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤: ä» MARKDOWN_MAX_CONCURRENT ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ 50ï¼‰

        è¿”å›:
            åŒ…å«æ‰€æœ‰è½¬æ¢ç»“æœçš„åˆ—è¡¨
        """
        import asyncio

        # ä½¿ç”¨é…ç½®çš„æœ€å¤§å¹¶å‘æ•°ï¼Œæˆ–ä½¿ç”¨å‚æ•°è¦†ç›–
        concurrent_limit = max_concurrent or self.max_concurrent

        # æ£€æŸ¥æ–‡ä»¶æ•°é‡æ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(file_paths) > self.max_batch_files:
            print(f"âš ï¸ è­¦å‘Š: æ–‡ä»¶æ•°é‡ {len(file_paths)} è¶…è¿‡æ‰¹å¤„ç†é™åˆ¶ {self.max_batch_files}")

        # åˆ›å»ºä¿¡å·é‡æ¥é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(concurrent_limit)

        async def convert_with_semaphore(file_path: str) -> Dict[str, Any]:
            """å¸¦ä¿¡å·é‡æ§åˆ¶çš„è½¬æ¢å‡½æ•°"""
            async with semaphore:
                print(f"ğŸ”„ å¼€å§‹è½¬æ¢: {file_path}")
                result = await self.convert_file(file_path, page_range)
                result["file_path"] = file_path  # æ·»åŠ æ–‡ä»¶è·¯å¾„åˆ°ç»“æœä¸­
                return result

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è½¬æ¢ä»»åŠ¡
        tasks = [convert_with_semaphore(fp) for fp in file_paths]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    "success": False,
                    "message": f"è½¬æ¢å¤±è´¥: {str(result)}",
                    "markdown": "",
                    "metadata": {},
                    "images": {},
                    "file_path": file_paths[i]
                })
            else:
                processed_results.append(result)

        return processed_results

    async def convert_multiple_file_bytes(
        self,
        files_data: list[tuple[bytes, str]],
        page_range: Optional[str] = None,
        max_concurrent: Optional[int] = None
    ) -> list[Dict[str, Any]]:
        """
        å¹¶å‘è½¬æ¢å¤šä¸ªæ–‡ä»¶å­—èŠ‚æµ

        å‚æ•°:
            files_data: æ–‡ä»¶æ•°æ®åˆ—è¡¨ï¼Œæ¯é¡¹ä¸º (file_bytes, filename) å…ƒç»„
            page_range: é¡µé¢èŒƒå›´ (ä¾‹å¦‚: "0,5-10,20")
            max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤: ä» MARKDOWN_MAX_CONCURRENT ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ 50ï¼‰

        è¿”å›:
            åŒ…å«æ‰€æœ‰è½¬æ¢ç»“æœçš„åˆ—è¡¨
        """
        import asyncio

        # ä½¿ç”¨é…ç½®çš„æœ€å¤§å¹¶å‘æ•°ï¼Œæˆ–ä½¿ç”¨å‚æ•°è¦†ç›–
        concurrent_limit = max_concurrent or self.max_concurrent

        # æ£€æŸ¥æ–‡ä»¶æ•°é‡æ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(files_data) > self.max_batch_files:
            print(f"âš ï¸ è­¦å‘Š: æ–‡ä»¶æ•°é‡ {len(files_data)} è¶…è¿‡æ‰¹å¤„ç†é™åˆ¶ {self.max_batch_files}")

        # åˆ›å»ºä¿¡å·é‡æ¥é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(concurrent_limit)

        async def convert_with_semaphore(file_bytes: bytes, filename: str) -> Dict[str, Any]:
            """å¸¦ä¿¡å·é‡æ§åˆ¶çš„è½¬æ¢å‡½æ•°"""
            async with semaphore:
                print(f"ğŸ”„ å¼€å§‹è½¬æ¢: {filename}")
                result = await self.convert_file_bytes(file_bytes, filename, page_range)
                result["filename"] = filename  # æ·»åŠ æ–‡ä»¶ååˆ°ç»“æœä¸­
                return result

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è½¬æ¢ä»»åŠ¡
        tasks = [convert_with_semaphore(fb, fn) for fb, fn in files_data]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    "success": False,
                    "message": f"è½¬æ¢å¤±è´¥: {str(result)}",
                    "markdown": "",
                    "metadata": {},
                    "images": {},
                    "filename": files_data[i][1]
                })
            else:
                processed_results.append(result)

        return processed_results